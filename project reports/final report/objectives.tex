We investigate how various CPU workloads and frequencies affect the performance of the deep learning task and system power under thermal design power (TDP) constraint. We fix GPU to do inference for an image classification task. Meanwhile, we run meaningful tasks on CPU to utilize the remaining resources of the embedded platform. Hence, we can better understand what is acceptable to run CPU without affecting the performance of the deep learning task. Moreover, we analyze how CPU-GPU workloads affect temperature values where CPU and GPU share the same power budget. Last but not least, we investigate the trade-off between the performance of the CPU workload and the performance of the deep learning task by investigating the instruction per cycle (IPC) for CPU as well as the latency for the deep learning task.